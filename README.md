
# Stock Price Prediction Project

**Authors**: Diego Lozano
**Last Updated**: August 7, 2025  

---

## Overview

This project develops a dynamic pipeline to predict the next-day closing price of stocks using machine learning, with Tesla (TSLA) as the primary focus. Designed for flexibility, it supports any stock symbol via command-line arguments. The project leverages linear regression models and is structured for automation, making it a robust demonstration of data science and DevOps skills.

---

## Project Goals

- Predict next-day closing stock prices using linear regression.  
- Support dynamic stock selection with TSLA as the initial stock.  
- Build an automated pipeline for data retrieval, processing, and modeling.

---

## Data Source

- **Source**: Alpha Vantage API (free tier, daily stock data).  
- **Time Frame**: One year of daily data (June 17, 2024 - June 16, 2025 for TSLA, ~250 rows after holidays).  
- **Features**: Previous day's closing price, daily trading volume, 5-day moving average.

---

## Model

- **Algorithm**: Linear regression, with two versions:  
  - Including outliers (RMSE=19.54, MAE=14.47, R²=0.77).  
  - Excluding outliers (RMSE=19.16, MAE=14.30, R²=0.78).  
- **Output**: Models saved as `.pkl` files in `models/` with timestamped names.

---

## Directory Structure

- `config/`: Configuration file (`config.json`) for settings (auto-generated).  
- `data/`: Raw (`raw/`), processed (`processed/`), intermediate (`intermediate/`), and outlier (`outliers/`) data.  
- `docs/`:  
  - `data_evaluation/`: Reports on data inspection.  
  - `model_evaluation/`: Reports on model performance.  
  - `reports/`: Final evaluation report summarizing project outcomes.  
- `logs/`: Log files for debugging and tracking.  
- `models/`: Trained models and history (`models_history.jsonl`).  
- `notebooks/`: Data inspection (`inspect_data.ipynb`) and model analysis (`model_analysis.ipynb`).  
- `plots/`: Visualizations from notebooks.  
- `scripts/`: Core scripts (`initialize_config.py`, `fetch_data.py`, `process_data.py`, `model.py`, `export_notebook.py`, etc.).  
- `spp/`: Utility modules (`data_utils.py`, `logging_utils.py`, `plot_utils.py`).

---

## Setup and Installation

Follow these steps to set up and run the stock price prediction project on your local machine.

1. **Clone the Repository**:  
   - Clone the project repository to your local machine and navigate to the project directory:  
     ```bash  
     git clone https://github.com/your-username/stock-price-prediction.git  
     cd stock-price-prediction  
     ```

2. **Set Up the Virtual Environment**:  
   - Create a Python virtual environment to manage dependencies:  
     ```bash  
     python3 -m venv venv  
     ```  
   - Activate the virtual environment:  
     - On Unix/Linux/MacOS:  
       ```bash  
       source venv/bin/activate  
       ```  
     - On Windows:  
       ```bash  
       venv\Scripts\activate  
       ```

3. **Install Dependencies**:  
   - Install the required Python packages listed in `requirements.txt`:  
     ```bash  
     pip install -r requirements.txt  
     ```

4. **Configuration**:  
   - The configuration file (`config.json`) is auto-generated by running `initialize_config.py`. To set it up:  
     ```bash  
     python scripts/initialize_config.py  
     ```  
   - Create a `.env` file in the project root and add your Alpha Vantage API key:  
     ```bash  
     echo "ALPHA_VANTAGE_API_KEY=YOUR_API_KEY_HERE" > .env  
     ```  
   - You can obtain a free API key from [Alpha Vantage](https://www.alphavantage.co/support/#api-key).  
   - **Note**: The stock symbol is provided via command-line arguments when running the pipeline, not set in `config.json`.

5. **Run the Pipeline Manually**:  
   - Execute the pipeline script with a stock symbol of your choice:  
     ```bash  
     ./run_pipeline.sh <stock_symbol>  
     ```  
   - Replace `<stock_symbol>` with a valid stock ticker (e.g., `TSLA` for Tesla). Example:  
     ```bash  
     ./run_pipeline.sh TSLA  
     ```  
   - **After running**, check `docs/reports/` for the final report and `plots/` if desired for visualizations.

---

## Additional Notes

- **Prerequisite**: If you plan to execute Jupyter notebooks (e.g., `inspect_data.ipynb`), ensure `papermill` is installed:  
  ```bash  
  pip install papermill  
  ```  
- **Deactivating the Virtual Environment**: When done, deactivate the environment with:  
  ```bash  
  deactivate  
  ```  
- **Troubleshooting**: If you encounter issues, check the `logs/` directory for detailed error messages.

---

## Automation

The pipeline can be automated to run at regular intervals using cron (for Unix/Linux/MacOS) or Task Scheduler (for Windows). This is ideal for keeping models up-to-date with the latest stock data.

### Steps to Set Up Automation with Cron

1. **Make the Script Executable**:  
   Ensure `run_pipeline.sh` is executable:  
   ```bash  
   chmod +x /path/to/stock-price-prediction/run_pipeline.sh  
   ```

2. **Open the Cron Editor**:  
   Run:  
   ```bash  
   crontab -e  
   ```

3. **Add the Cron Job**:  
   Add this line to run the pipeline every Monday at 8 AM, providing the stock symbol (e.g., TSLA):  
   ```bash  
   0 8 * * 1 /path/to/stock-price-prediction/run_pipeline.sh TSLA >> /path/to/logs/cron.log 2>&1  
   ```  
   Replace `/path/to/` with your project’s actual path and `TSLA` with your desired stock symbol.

4. **Save and Exit**:  
   Save the changes and exit the editor. The cron job is now scheduled.

5. **Monitor the Pipeline**:  
   Check `logs/cron.log` and `logs/pipeline.log` after the scheduled run to confirm execution.

For more details on setting up automation, refer to `docs/automation.md` (if available).
